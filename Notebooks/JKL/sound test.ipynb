{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65538049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import scipy\n",
    "from datetime import datetime\n",
    "from diffusers import AudioLDM2Pipeline\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f076005",
   "metadata": {},
   "source": [
    "## 1. Audioldm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1552c567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_dotenv(dotenv_path=os.path.join(\"..\", \".env\"))\n",
    "# token = os.getenv(\"HUGGING_FACE_HUB_TOKEN\")\n",
    "\n",
    "# # ì‹¤ì œ ì¸ì¦ í…ŒìŠ¤íŠ¸\n",
    "# print(\"ðŸ” ì¸ì¦ëœ ì‚¬ìš©ìž ì •ë³´:\")\n",
    "# whoami(token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fb62b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiocraft.models import AudioGen\n",
    "from audiocraft.data.audio import audio_write\n",
    "import torch\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ\n",
    "model = AudioGen.get_pretrained(\"facebook/audiogen-medium\")\n",
    "model.set_generation_params(duration=5)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ (êµ¬ì²´ì  ë¬˜ì‚¬, ê¸°ê³„ ì†ŒìŒ ë°°ì œ, ìžì—°ìŠ¤ëŸ¬ìš´ ë¬˜ì‚¬)\n",
    "prompt = [\n",
    "    \"A person digging soil with a metal shovel, planting seeds, covering them gently with soil, \"\n",
    "    \"natural outdoor environment, no mechanical noises, birds chirping softly far away.\"\n",
    "]\n",
    "\n",
    "# ì˜¤ë””ì˜¤ ìƒì„± & ì €ìž¥ (4ê°œ ìƒì„±)\n",
    "for i in range(4):\n",
    "    wav = model.generate(prompt)[0].cpu()\n",
    "    filename = f\"planting_seeds_v{i+1}\"\n",
    "    audio_write(filename, wav, model.sample_rate, strategy=\"loudness\")\n",
    "    print(f\"âœ… ì €ìž¥ ì™„ë£Œ: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564a0bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import torch\n",
    "from diffusers import AudioLDM2Pipeline\n",
    "\n",
    "# load the pipeline\n",
    "repo_id = \"cvssp/audioldm2\"\n",
    "pipe = AudioLDM2Pipeline.from_pretrained(repo_id, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "# define the prompts\n",
    "prompt = \"Soft thuds of moist soil being gently pressed as small seeds are planted, accompanied by subtle rustling of leaves and distant chirping of birds in a quiet garden.\"\n",
    "negative_prompt = \"Low quality.\"\n",
    "\n",
    "# set the seed\n",
    "generator = torch.Generator(\"cuda\").manual_seed(0)\n",
    "\n",
    "# run the generation\n",
    "audio = pipe(\n",
    "    prompt,\n",
    "    negative_prompt=negative_prompt,\n",
    "    num_inference_steps=200,\n",
    "    audio_length_in_s=3.0,\n",
    "    num_waveforms_per_prompt=3,\n",
    ").audios\n",
    "\n",
    "# save the best audio sample (index 0) as a .wav file\n",
    "scipy.io.wavfile.write(\"seeds_test3.wav\", rate=16000, data=audio[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89454f1",
   "metadata": {},
   "source": [
    "## 2. MusicGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be012242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U git+https://github.com/facebookresearch/audiocraft#egg=audiocraft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656483ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\envs\\audioldm2_env\\lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub\\models--facebook--musicgen-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\user\\miniconda3\\envs\\audioldm2_env\\lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "CLIPPING 0.wav happening with proba (a bit of clipping is okay): 0.0017812500009313226 maximum scale:  1.1532424688339233\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "from audiocraft.models import MusicGen\n",
    "from audiocraft.data.audio import audio_write\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ\n",
    "model = MusicGen.get_pretrained('facebook/musicgen-large')\n",
    "model.set_generation_params(duration=8)  # 8ì´ˆ ê¸¸ì´ì˜ ì˜¤ë””ì˜¤ ìƒì„±\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "descriptions = ['lo-fi music with a soothing melody']\n",
    "\n",
    "# ì˜¤ë””ì˜¤ ìƒì„±\n",
    "wav = model.generate(descriptions)\n",
    "\n",
    "# ì˜¤ë””ì˜¤ ì €ìž¥\n",
    "for idx, one_wav in enumerate(wav):\n",
    "    audio_write(f'{idx}.wav', one_wav.cpu(), model.sample_rate, strategy=\"loudness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db498557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiocraft.models import MusicGen\n",
    "from audiocraft.data.audio import audio_write\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ (ì‚¬ì „ í•™ìŠµëœ large ëª¨ë¸)\n",
    "model = MusicGen.get_pretrained('facebook/musicgen-large')\n",
    "model.set_generation_params(duration=8)  # ìƒì„±í•  ê¸¸ì´ (ì´ˆ)\n",
    "\n",
    "# ðŸŽ¯ í”„ë¡¬í”„íŠ¸\n",
    "descriptions = [\"The ambient sound of a kitchen stew gently boiling, with soft bubbling and simmering, cozy atmosphere\"]\n",
    "\n",
    "# ì˜¤ë””ì˜¤ ìƒì„±\n",
    "wav = model.generate(descriptions)\n",
    "\n",
    "# ì €ìž¥\n",
    "audio_write(\"musicgen_stew_bubbling\", wav[0].cpu(), model.sample_rate, strategy=\"loudness\")\n",
    "print(\"âœ… ì €ìž¥ ì™„ë£Œ: musicgen_stew_bubbling.wav\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6635d94c",
   "metadata": {},
   "source": [
    "## 3. AudioGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc4fb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchaudio\n",
    "# from audiocraft.models import AudioGen\n",
    "# from audiocraft.data.audio import audio_write\n",
    "\n",
    "# # ëª¨ë¸ ë¡œë“œ\n",
    "# model = AudioGen.get_pretrained('facebook/audiogen-medium')\n",
    "# model.set_generation_params(duration=5)  # 5ì´ˆ ê¸¸ì´ì˜ ì˜¤ë””ì˜¤ ìƒì„±\n",
    "\n",
    "# # í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "# descriptions = ['planting seeds', '']\n",
    "\n",
    "# # ì˜¤ë””ì˜¤ ìƒì„±\n",
    "# wav = model.generate(descriptions)\n",
    "\n",
    "# # ì˜¤ë””ì˜¤ ì €ìž¥\n",
    "# for idx, one_wav in enumerate(wav):\n",
    "#     audio_write(f'{idx}.wav', one_wav.cpu(), model.sample_rate, strategy=\"loudness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0135366",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Documents\\GitHub\\sound_310\\lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ìž¥ ì™„ë£Œ: farming_v1\n",
      "âœ… ì €ìž¥ ì™„ë£Œ: farming_v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLIPPING farming_v3 happening with proba (a bit of clipping is okay): 0.00039999998989515007 maximum scale:  1.8202755451202393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ìž¥ ì™„ë£Œ: farming_v3\n",
      "âœ… ì €ìž¥ ì™„ë£Œ: farming_v4\n"
     ]
    }
   ],
   "source": [
    "# from audiocraft.models import AudioGen\n",
    "# from audiocraft.data.audio import audio_write\n",
    "\n",
    "# # ëª¨ë¸ ë¡œë“œ\n",
    "# model = AudioGen.get_pretrained(\"facebook/audiogen-medium\")\n",
    "\n",
    "# # ìƒì„±í•  ì˜¤ë””ì˜¤ ê¸¸ì´ ì„¤ì •\n",
    "# model.set_generation_params(duration=4)\n",
    "\n",
    "# # í”„ë¡¬í”„íŠ¸\n",
    "# prompt = [\n",
    "#     \"Soft thuds of moist soil being gently pressed as small seeds are planted, accompanied by subtle rustling of leaves and distant chirping of birds in a quiet garden.\"\n",
    "# ]\n",
    "\n",
    "# # ì˜¤ë””ì˜¤ ìƒì„±\n",
    "# wav_outputs = model.generate(prompt)\n",
    "\n",
    "# # ì €ìž¥\n",
    "# audio_write(\"planting_seeds_test\", wav_outputs[0].cpu(), model.sample_rate, strategy=\"loudness\")\n",
    "# print(\"âœ… ì˜¤ë””ì˜¤ ìƒì„± ì™„ë£Œ!\")\n",
    "\n",
    "from audiocraft.models import AudioGen\n",
    "from audiocraft.data.audio import audio_write\n",
    "import torch\n",
    "\n",
    "# âœ… ëª¨ë¸ ë¡œë“œ\n",
    "model = AudioGen.get_pretrained(\"facebook/audiogen-medium\")\n",
    "\n",
    "# âœ… ìƒì„± í’ˆì§ˆ ì„¸íŒ… (sampling params)\n",
    "model.set_generation_params(\n",
    "    duration=5,         # ìƒì„±í•  ì˜¤ë””ì˜¤ ê¸¸ì´ (ì´ˆ)\n",
    "    temperature=0.7,    # ì°½ì˜ì„± ì •ë„ (ë‚®ì¶œìˆ˜ë¡ ì•ˆì •ì )\n",
    "    top_p=0.9,          # í™•ë¥ ì  ìƒ˜í”Œë§ ë²”ìœ„ (ë‚®ì¶œìˆ˜ë¡ ì¼ê´€ì„±â†‘)\n",
    ")\n",
    "\n",
    "# âœ… í”„ë¡¬í”„íŠ¸ (í›¨ì”¬ êµ¬ì²´ì ìœ¼ë¡œ ê°œì„ )\n",
    "prompt = [\n",
    "    \"digging with a shovel\"\n",
    "]\n",
    "\n",
    "# âœ… ì˜¤ë””ì˜¤ ìƒì„± & ì €ìž¥\n",
    "for i in range(4):\n",
    "    wav = model.generate(prompt)[0].cpu()\n",
    "    filename = f\"farming_v{i+1}\"\n",
    "    audio_write(filename, wav, model.sample_rate, strategy=\"loudness\")\n",
    "    print(f\"âœ… ì €ìž¥ ì™„ë£Œ: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6108302d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¥ CUDA ê°€ëŠ¥? True\n",
      "ðŸ§  GPU ì‚¬ìš© ì¤‘: NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"ðŸ”¥ CUDA ê°€ëŠ¥?\", torch.cuda.is_available())\n",
    "print(\"ðŸ§  GPU ì‚¬ìš© ì¤‘:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5553aa4",
   "metadata": {},
   "source": [
    "# 8. ezaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ce6f39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Documents\\GitHub\\ProjectISG-AI\\Notebooks\\JKL\\soundctm\\soundctm\\EzAudio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'EzAudio'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting alias_free_torch (from -r requirements.txt (line 1))\n",
      "  Using cached alias_free_torch-0.0.6-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: diffusers in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from -r requirements.txt (line 2)) (0.26.2)\n",
      "Requirement already satisfied: einops in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from -r requirements.txt (line 3)) (0.7.0)\n",
      "Requirement already satisfied: librosa in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from -r requirements.txt (line 4)) (0.9.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from -r requirements.txt (line 5)) (2.0.2)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from -r requirements.txt (line 6)) (6.0.1)\n",
      "Requirement already satisfied: soundfile in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from -r requirements.txt (line 7)) (0.10.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from -r requirements.txt (line 8)) (4.66.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from -r requirements.txt (line 9)) (4.36.2)\n",
      "Collecting vector_quantize_pytorch (from -r requirements.txt (line 10))\n",
      "  Using cached vector_quantize_pytorch-1.22.15-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from -r requirements.txt (line 11)) (2.2.2+cu121)\n",
      "Collecting julius (from -r requirements.txt (line 12))\n",
      "  Using cached julius-0.2.7.tar.gz (59 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting torch_stoi (from -r requirements.txt (line 13))\n",
      "  Using cached torch_stoi-0.2.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting flatten-dict (from -r requirements.txt (line 14))\n",
      "  Using cached flatten_dict-0.4.2-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting tensorboard (from -r requirements.txt (line 15))\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting randomname (from -r requirements.txt (line 16))\n",
      "  Using cached randomname-0.2.1.tar.gz (64 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting argbind (from -r requirements.txt (line 17))\n",
      "  Using cached argbind-0.3.9.tar.gz (17 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting sentencepiece (from -r requirements.txt (line 18))\n",
      "  Using cached sentencepiece-0.2.0-cp310-cp310-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: accelerate in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from -r requirements.txt (line 19)) (0.20.3)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from diffusers->-r requirements.txt (line 2)) (6.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from diffusers->-r requirements.txt (line 2)) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.2 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from diffusers->-r requirements.txt (line 2)) (0.30.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from diffusers->-r requirements.txt (line 2)) (1.23.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from diffusers->-r requirements.txt (line 2)) (2023.8.8)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from diffusers->-r requirements.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from diffusers->-r requirements.txt (line 2)) (0.5.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from diffusers->-r requirements.txt (line 2)) (10.4.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from librosa->-r requirements.txt (line 4)) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from librosa->-r requirements.txt (line 4)) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from librosa->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from librosa->-r requirements.txt (line 4)) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.0.10 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from librosa->-r requirements.txt (line 4)) (5.2.1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from librosa->-r requirements.txt (line 4)) (0.4.2)\n",
      "Requirement already satisfied: numba>=0.45.1 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from librosa->-r requirements.txt (line 4)) (0.58.1)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from librosa->-r requirements.txt (line 4)) (1.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from librosa->-r requirements.txt (line 4)) (23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from pandas->-r requirements.txt (line 5)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from pandas->-r requirements.txt (line 5)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from pandas->-r requirements.txt (line 5)) (2025.2)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from soundfile->-r requirements.txt (line 7)) (1.17.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from tqdm->-r requirements.txt (line 8)) (0.4.6)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from transformers->-r requirements.txt (line 9)) (0.15.2)\n",
      "Collecting einops (from -r requirements.txt (line 3))\n",
      "  Using cached einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting einx>=0.3.0 (from vector_quantize_pytorch->-r requirements.txt (line 10))\n",
      "  Using cached einx-0.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: torch>=2.0 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from vector_quantize_pytorch->-r requirements.txt (line 10)) (2.2.2+cu121)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from torch>=2.0->vector_quantize_pytorch->-r requirements.txt (line 10)) (4.13.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from torch>=2.0->vector_quantize_pytorch->-r requirements.txt (line 10)) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from torch>=2.0->vector_quantize_pytorch->-r requirements.txt (line 10)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from torch>=2.0->vector_quantize_pytorch->-r requirements.txt (line 10)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from torch>=2.0->vector_quantize_pytorch->-r requirements.txt (line 10)) (2023.6.0)\n",
      "Collecting pystoi (from torch_stoi->-r requirements.txt (line 13))\n",
      "  Using cached pystoi-0.4.1-py2.py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: six<2.0,>=1.12 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from flatten-dict->-r requirements.txt (line 14)) (1.17.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from tensorboard->-r requirements.txt (line 15)) (2.0.0)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard->-r requirements.txt (line 15))\n",
      "  Downloading grpcio-1.71.0-cp310-cp310-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard->-r requirements.txt (line 15))\n",
      "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from tensorboard->-r requirements.txt (line 15)) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from tensorboard->-r requirements.txt (line 15)) (57.4.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->-r requirements.txt (line 15))\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard->-r requirements.txt (line 15))\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting fire (from randomname->-r requirements.txt (line 16))\n",
      "  Using cached fire-0.7.0.tar.gz (87 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting docstring-parser (from argbind->-r requirements.txt (line 17))\n",
      "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from accelerate->-r requirements.txt (line 19)) (7.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 7)) (2.22)\n",
      "Collecting frozendict (from einx>=0.3.0->vector_quantize_pytorch->-r requirements.txt (line 10))\n",
      "  Using cached frozendict-2.4.6-cp310-cp310-win_amd64.whl.metadata (23 kB)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from numba>=0.45.1->librosa->-r requirements.txt (line 4)) (0.41.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from pooch>=1.0->librosa->-r requirements.txt (line 4)) (4.3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from requests->diffusers->-r requirements.txt (line 2)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from requests->diffusers->-r requirements.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from requests->diffusers->-r requirements.txt (line 2)) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from requests->diffusers->-r requirements.txt (line 2)) (2025.1.31)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from scikit-learn>=0.19.1->librosa->-r requirements.txt (line 4)) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 15)) (2.1.5)\n",
      "Collecting termcolor (from fire->randomname->-r requirements.txt (line 16))\n",
      "  Using cached termcolor-3.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from importlib-metadata->diffusers->-r requirements.txt (line 2)) (3.21.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\documents\\github\\sound_310\\lib\\site-packages (from sympy->torch>=2.0->vector_quantize_pytorch->-r requirements.txt (line 10)) (1.3.0)\n",
      "Using cached alias_free_torch-0.0.6-py3-none-any.whl (9.7 kB)\n",
      "Using cached vector_quantize_pytorch-1.22.15-py3-none-any.whl (47 kB)\n",
      "Using cached einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Using cached torch_stoi-0.2.3-py3-none-any.whl (8.1 kB)\n",
      "Using cached flatten_dict-0.4.2-py2.py3-none-any.whl (9.7 kB)\n",
      "Using cached tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 991.5/991.5 kB 48.6 MB/s eta 0:00:00\n",
      "Using cached einx-0.3.0-py3-none-any.whl (102 kB)\n",
      "Downloading grpcio-1.71.0-cp310-cp310-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.3/4.3 MB 129.6 MB/s eta 0:00:00\n",
      "Downloading markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Using cached pystoi-0.4.1-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading frozendict-2.4.6-cp310-cp310-win_amd64.whl (37 kB)\n",
      "Using cached termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
      "Building wheels for collected packages: julius, randomname, argbind, fire\n",
      "  Building wheel for julius (pyproject.toml): started\n",
      "  Building wheel for julius (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=22018 sha256=c32b94b3fb5864f7dd2cbebe13ee39b449ed204b67af7444d909e035e671abee\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\b9\\b2\\05\\f883527ffcb7f2ead5438a2c23439aa0c881eaa9a4c80256f4\n",
      "  Building wheel for randomname (pyproject.toml): started\n",
      "  Building wheel for randomname (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for randomname: filename=randomname-0.2.1-py3-none-any.whl size=89313 sha256=9339e83f12d8bdd2336a9397bda913a31c2fe7abb80e8cc25896f144cbe657af\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\10\\50\\8a\\25f3820d26a431ffed1834d72ff2eb349123cf2b44c5a45727\n",
      "  Building wheel for argbind (pyproject.toml): started\n",
      "  Building wheel for argbind (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for argbind: filename=argbind-0.3.9-py2.py3-none-any.whl size=11896 sha256=be389eb5128a60d9f39d83f4e5c00fa6c757e68186ba0a7c8777ce5f9e114c47\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\ed\\ab\\ff\\64eb14a776ae6525e1a7d6ad38b73ba020ecc4262d83a7889d\n",
      "  Building wheel for fire (pyproject.toml): started\n",
      "  Building wheel for fire (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114349 sha256=147db0beea4df9b0a86fae9fda160009537be7bcfed5149dec6817a4502c5277\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\19\\39\\2f\\2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
      "Successfully built julius randomname argbind fire\n",
      "Installing collected packages: sentencepiece, werkzeug, termcolor, tensorboard-data-server, markdown, grpcio, frozendict, flatten-dict, einops, docstring-parser, alias_free_torch, tensorboard, pystoi, fire, einx, argbind, vector_quantize_pytorch, randomname, julius, torch_stoi\n",
      "  Attempting uninstall: einops\n",
      "    Found existing installation: einops 0.7.0\n",
      "    Uninstalling einops-0.7.0:\n",
      "      Successfully uninstalled einops-0.7.0\n",
      "Successfully installed alias_free_torch-0.0.6 argbind-0.3.9 docstring-parser-0.16 einops-0.8.1 einx-0.3.0 fire-0.7.0 flatten-dict-0.4.2 frozendict-2.4.6 grpcio-1.71.0 julius-0.2.7 markdown-3.8 pystoi-0.4.1 randomname-0.2.1 sentencepiece-0.2.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 termcolor-3.0.1 torch_stoi-0.2.3 vector_quantize_pytorch-1.22.15 werkzeug-3.1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Documents\\GitHub\\sound_310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\user\\Documents\\GitHub\\sound_310\\lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\user\\Documents\\GitHub\\sound_310\\lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\user\\Documents\\GitHub\\sound_310\\lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'cached_download' from 'huggingface_hub' (c:\\Users\\user\\Documents\\GitHub\\sound_310\\lib\\site-packages\\huggingface_hub\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install -r requirements.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# ì˜ˆì‹œ ì½”ë“œ\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mezaudio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EzAudio\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msoundfile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msf\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\Documents\\GitHub\\ProjectISG-AI\\Notebooks\\JKL\\soundctm\\soundctm\\EzAudio\\api\\ezaudio.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01maccelerate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Accelerator\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m T5Tokenizer, T5EncoderModel\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdiffusers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DDIMScheduler\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconditioners\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MaskDiT\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautoencoder_wrapper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Autoencoder\n",
      "File \u001b[1;32mc:\\Users\\user\\Documents\\GitHub\\sound_310\\lib\\site-packages\\diffusers\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.26.2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      6\u001b[0m     DIFFUSERS_SLOW_IMPORT,\n\u001b[0;32m      7\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[0;32m      8\u001b[0m     _LazyModule,\n\u001b[0;32m      9\u001b[0m     is_flax_available,\n\u001b[0;32m     10\u001b[0m     is_k_diffusion_available,\n\u001b[0;32m     11\u001b[0m     is_librosa_available,\n\u001b[0;32m     12\u001b[0m     is_note_seq_available,\n\u001b[0;32m     13\u001b[0m     is_onnx_available,\n\u001b[0;32m     14\u001b[0m     is_scipy_available,\n\u001b[0;32m     15\u001b[0m     is_torch_available,\n\u001b[0;32m     16\u001b[0m     is_torchsde_available,\n\u001b[0;32m     17\u001b[0m     is_transformers_available,\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Lazy Import based on\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# https://github.com/huggingface/transformers/blob/main/src/transformers/__init__.py\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# When adding a new object to this init, please add it to `_import_structure`. The `_import_structure` is a dictionary submodule to list of object names,\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# and is used to defer the actual importing for when the objects are requested.\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# This way `import diffusers` provides the names in the namespace without actually importing anything (and especially none of the backends).\u001b[39;00m\n\u001b[0;32m     28\u001b[0m _import_structure \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfiguration_utils\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfigMixin\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m     ],\n\u001b[0;32m     51\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\user\\Documents\\GitHub\\sound_310\\lib\\site-packages\\diffusers\\utils\\__init__.py:38\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deprecate\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m replace_example_docstring\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_modules_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_class_from_dynamic_module\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexport_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m export_to_gif, export_to_obj, export_to_ply, export_to_video\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     41\u001b[0m     PushToHubMixin,\n\u001b[0;32m     42\u001b[0m     _add_variant,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m     http_user_agent,\n\u001b[0;32m     46\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\user\\Documents\\GitHub\\sound_310\\lib\\site-packages\\diffusers\\utils\\dynamic_modules_utils.py:28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Optional, Union\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m request\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cached_download, hf_hub_download, model_info\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m validate_hf_hub_args\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m version\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'cached_download' from 'huggingface_hub' (c:\\Users\\user\\Documents\\GitHub\\sound_310\\lib\\site-packages\\huggingface_hub\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# ì„¤ì¹˜\n",
    "!git clone https://github.com/haidog-yaqub/EzAudio.git\n",
    "%cd EzAudio\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# ì˜ˆì‹œ ì½”ë“œ\n",
    "from api.ezaudio import EzAudio\n",
    "import torch\n",
    "import soundfile as sf\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "ezaudio = EzAudio(model_name='s3_xl', device=device)\n",
    "\n",
    "prompt = \"A dog barking in the distance\"\n",
    "sr, audio = ezaudio.generate_audio(prompt)\n",
    "sf.write(f'{prompt}.wav', audio, sr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sound_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
